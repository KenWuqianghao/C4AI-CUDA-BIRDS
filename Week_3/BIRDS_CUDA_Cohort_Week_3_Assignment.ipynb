{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n714FyEdcaX"
      },
      "source": [
        "**Q1. Write a simple CUDA kernel that takes an array of integers and doubles each element.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Source files will be saved in \"/var/folders/pf/fm0v0g_52r754cfv3r4lqv980000gn/T/tmpefn0a7_d\".\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nxLk8gLmcx1_",
        "outputId": "4f45be7b-c07a-49bd-d589-9455645ec949"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#include <iostream>\\n#include <cuda_runtime.h>\\n\\nusing namespace std;\\n\\n__global__ void add_basic()\\n{\\n    // COMPLETE THIS\\n}\\n\\nint main()\\n{\\n    // COMPLETE THIS\\n\\n    // Wait for GPU to finish before accessing on host\\n    cudaDeviceSynchronize();\\n\\n    return 0;\\n}\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "! touch add_basic.cu\n",
        "\"\"\"\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// CUDA Kernel function to double each element in the array\n",
        "__global__ void add_basic(int *data, int count)\n",
        "{\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (index < count) {\n",
        "        data[index] *= 2;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int *h_data;     // Host array\n",
        "    int *d_data;     // Device array\n",
        "    int n = 1024;    // Size of the array\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_data = (int*)malloc(n * sizeof(int));\n",
        "\n",
        "    // Initialize host array\n",
        "    for(int i = 0; i < n; i++) {\n",
        "        h_data[i] = i;  // Example data\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc((void**)&d_data, n * sizeof(int));\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_data, h_data, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch the kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    add_basic<<<blocksPerGrid, threadsPerBlock>>>(d_data, n);\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copy data back from device to host\n",
        "    cudaMemcpy(h_data, d_data, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Example output\n",
        "    for(int i = 0; i < 10; i++) {  // Print the first 10 elements\n",
        "        printf(\"%d \", h_data[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_data);\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_data);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IFT0vwhdhKe"
      },
      "source": [
        "**Q2. Write a CUDA kernel to initialize an array of integers with the index value.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ozXZzwCsdhcu",
        "outputId": "b87935d6-3ed2-4d56-b3e7-12cd7bdd4973"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#include <iostream>\\n#include <cuda_runtime.h>\\n\\nusing namespace std;\\n\\n__global__ void initialize_array(int *array)\\n{\\n    // Calculate the index for the current thread\\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\\n\\n     // Initialize the array element at the calculated index with its index value\\n    // Hint: Use the \\'index\\' variable to assign the value\\n    // COMPLETE THIS\\n\\n}\\n\\nint main()\\n{\\n    const int array_size = 10;\\n    int *d_array;\\n\\n    // Allocate memory on GPU\\n    cudaMalloc((void**)&d_array, array_size * sizeof(int));\\n\\n    // Launch the CUDA kernel to initialize the array\\n    // Hint: Use the <<<...>>> syntax to specify the grid and block dimensions\\n    // COMPLETE THIS\\n\\n    // Copy data from device to host\\n    int h_array[array_size];\\n    cudaMemcpy(h_array, d_array, array_size * sizeof(int), cudaMemcpyDeviceToHost);\\n\\n    // Print the initialized array\\n    cout << \"Initialized Array:\" << endl;\\n    for (int i = 0; i < array_size; ++i) {\\n        cout << h_array[i] << \" \";\\n    }\\n    cout << endl;\\n\\n    // Free GPU memory\\n    cudaFree(d_array);\\n\\n    // Wait for GPU to finish before accessing on host\\n    cudaDeviceSynchronize();\\n\\n    return 0;\\n}\\n\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "! touch add_basic.cu\n",
        "\"\"\"\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// CUDA Kernel function to initialize each element of the array with its index\n",
        "__global__ void initialize_array(int *array)\n",
        "{\n",
        "    // Calculate the index for the current thread\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Initialize the array element at the calculated index with its index value\n",
        "    array[index] = index;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int array_size = 10;\n",
        "    int *d_array;\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    cudaMalloc((void**)&d_array, array_size * sizeof(int));\n",
        "\n",
        "    // Launch the CUDA kernel to initialize the array\n",
        "    int threadsPerBlock = 5; // Example: 5 threads per block\n",
        "    int blocksPerGrid = (array_size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    initialize_array<<<blocksPerGrid, threadsPerBlock>>>(d_array);\n",
        "\n",
        "    // Copy data from device to host\n",
        "    int h_array[array_size];\n",
        "    cudaMemcpy(h_array, d_array, array_size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the initialized array\n",
        "    cout << \"Initialized Array:\" << endl;\n",
        "    for (int i = 0; i < array_size; ++i) {\n",
        "        cout << h_array[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    // Free GPU memory\n",
        "    cudaFree(d_array);\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uewwr30fg-R"
      },
      "source": [
        "**Q3 [OPTIONAL]. How do you check for and handle errors in CUDA API calls and kernel launches?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYdRBoA5fg1X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
