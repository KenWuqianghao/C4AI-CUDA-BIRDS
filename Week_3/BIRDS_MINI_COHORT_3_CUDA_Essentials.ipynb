{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5r8XLVm2xTz"
      },
      "outputs": [],
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccOIY6F2tkF"
      },
      "source": [
        "## Mandatory CUDA Hello World"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "pU6hVmq02nL8",
        "outputId": "9f70b314-fcfc-4f62-c746-8ab90e05c65b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#include <iostream>\\n#include <cuda_runtime.h>\\n\\nusing namespace std;\\n\\n__global__ void helloFromGPU()\\n{\\n    /*\\n        We can\\'t use cout in device. Why?\\n        Because The GPU does not have access to standard\\n        output streams like std::cout, which are managed\\n        by the host(CPU) operating system.\\n    */\\n    printf(\"Hello World from GPU!\\n\");\\n}\\n\\nint main()\\n{\\n    // Print from host\\n    cout<<\"Hello World from CPU!\"<<\"\\n\";\\n\\n    /*\\n        Launch a kernel on the GPU with one thread to\\n        print from GPU\\n    */\\n    helloFromGPU<<<1, 1>>>();\\n\\n    // Wait for GPU to finish before accessing on host\\n    cudaDeviceSynchronize();\\n\\n    return 0;\\n}\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "! touch hello_world.cu\n",
        "\"\"\"\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void helloFromGPU()\n",
        "{\n",
        "    /*\n",
        "        We can't use cout in device. Why?\n",
        "        Because The GPU does not have access to standard\n",
        "        output streams like std::cout, which are managed\n",
        "        by the host(CPU) operating system.\n",
        "    */\n",
        "    printf(\"Hello World from GPU!\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // Print from host\n",
        "    cout<<\"Hello World from CPU!\"<<\"\\n\";\n",
        "\n",
        "    /*\n",
        "        Launch a kernel on the GPU with one thread to\n",
        "        print from GPU\n",
        "    */\n",
        "    helloFromGPU<<<1, 1>>>();\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLd4TQP336O3",
        "outputId": "23661547-98a8-475f-f1b8-0599c2695ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World from CPU!\n",
            "Hello World from GPU!\n"
          ]
        }
      ],
      "source": [
        "! nvcc hello_world.cu -o hello_world\n",
        "! ./hello_world"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1mZMiEW4PyK"
      },
      "outputs": [],
      "source": [
        "! touch addition.cu\n",
        "\"\"\"\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "// Kernel function to add the elements of two arrays\n",
        "__global__ void add(int n, float *x, float *y)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "  for (int i = index; i < n; i += stride)\n",
        "    y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  long long int N = 1000000;\n",
        "  double *x, *y;\n",
        "\n",
        "  // Allocate Unified Memory â€“ accessible from CPU or GPU\n",
        "  cudaMallocManaged(&x, N*sizeof(float));\n",
        "  cudaMallocManaged(&y, N*sizeof(float));\n",
        "\n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0;\n",
        "    y[i] = 2.0;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the GPU\n",
        "  add<<<1, 1>>>(N, x, y);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i]-3.0));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(x);\n",
        "  cudaFree(y);\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrRJEjJKYsTQ"
      },
      "outputs": [],
      "source": [
        "! nvcc addition.cu -o addition\n",
        "! ./addition"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
