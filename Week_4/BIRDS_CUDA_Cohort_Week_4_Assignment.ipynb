{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSs2jkUOitMt",
        "outputId": "438d4bd0-f640-4978-8545-7ec1cec1dc62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /opt/homebrew/Caskroom/miniforge/base/envs/cuda/lib/python3.12/site-packages (1.2.1)\n",
            "Source files will be saved in \"/var/folders/pf/fm0v0g_52r754cfv3r4lqv980000gn/T/tmp0l2e27hz\".\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REqGCsKtjKAi"
      },
      "source": [
        "**Q1. Write a simple CUDA kernel that gives the sum of maximum element of 2 vectors and profile it for:**\n",
        "\n",
        "- Execution on 1 thread and 1 block\n",
        "- Execution on all threads of 1 block\n",
        "- Execution on all threads of n blocks. Deciding n is upto you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2x9RfFb1laSU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#include <stdio.h>\\n#include <cuda.h>\\n__global__ void maxElementKernel(float *vec, float *result, int n) {\\n    int idx = threadIdx.x + blockIdx.x * blockDim.x;\\n    extern __shared__ float sdata[];\\n\\n    // Perform reduction to find the max element\\n    for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\\n        if (threadIdx.x < s) {\\n            sdata[threadIdx.x] = max(sdata[threadIdx.x], sdata[threadIdx.x + s]);\\n        }\\n        __syncthreads();\\n    }\\n\\n    // Write result for this block to global mem\\n    if (threadIdx.x == 0) {\\n        result[blockIdx.x] = sdata[0];\\n    }\\n}\\n\\n__global__ void sumOfMaxElements(float *vec1, float *vec2, float *result, int n) {\\n    __shared__ float max1;\\n    __shared__ float max2;\\n\\n    // Find max of first vector\\n    maxElementKernel<<<1, blockDim.x, blockDim.x * sizeof(float)>>>(vec1, &max1, n);\\n    cudaDeviceSynchronize();\\n\\n    // Find max of second vector\\n    maxElementKernel<<<1, blockDim.x, blockDim.x * sizeof(float)>>>(vec2, &max2, n);\\n    cudaDeviceSynchronize();\\n\\n    // Sum the max elements and store the result\\n    if (threadIdx.x == 0) {\\n        result[0] = max1 + max2;\\n    }\\n}\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!touch max_vector.cu\n",
        "\"\"\"\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "__global__ void maxElementKernel(float *vec, float *result, int n) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    extern __shared__ float sdata[];\n",
        "\n",
        "    // Perform reduction to find the max element\n",
        "    for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "        if (threadIdx.x < s) {\n",
        "            sdata[threadIdx.x] = max(sdata[threadIdx.x], sdata[threadIdx.x + s]);\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write result for this block to global mem\n",
        "    if (threadIdx.x == 0) {\n",
        "        result[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sumOfMaxElements(float *vec1, float *vec2, float *result, int n) {\n",
        "    __shared__ float max1;\n",
        "    __shared__ float max2;\n",
        "\n",
        "    // Find max of first vector\n",
        "    maxElementKernel<<<1, blockDim.x, blockDim.x * sizeof(float)>>>(vec1, &max1, n);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Find max of second vector\n",
        "    maxElementKernel<<<1, blockDim.x, blockDim.x * sizeof(float)>>>(vec2, &max2, n);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Sum the max elements and store the result\n",
        "    if (threadIdx.x == 0) {\n",
        "        result[0] = max1 + max2;\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvcc -o max_vector max_vector.cu\n",
        "!nvprof ./max_vector 1 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvcc -o max_vector max_vector.cu\n",
        "!nvprof ./max_vector 1024 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvcc -o max_vector max_vector.cu\n",
        "!nvprof ./max_vector 1024 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eExCZ2C8lbCs"
      },
      "source": [
        "**Q2.[OPTIONAL] Write a simple CUDA kernel that does matrix multiplication of 2 matrices.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8UFMF6all5l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
