{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52wqeYbcqFkM"
      },
      "outputs": [],
      "source": [
        "!apt install nvidia-cuda-toolkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QDzo_rKhtnI"
      },
      "source": [
        "## QUESTION 1\n",
        "\n",
        "The following code snippet performs matrix multiplication in CUDA, fill in the // Your code here part in the following snippet and run it to obtain the correct answer for given matrices A and B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kntw99sIqD0j"
      },
      "outputs": [],
      "source": [
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Kernel function for matrix multiplication\n",
        "__global__ void matrixMulKernel(float *A, float *B, float *C, int m, int n, int p) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row < m && col < p) {\n",
        "        float sum = 0.0;\n",
        "        for (int k = 0; k < n; k++) {\n",
        "            sum += A[row * n + k] * B[k * p + col];\n",
        "        }\n",
        "        C[row * p + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int m = 2, n = 2, p = 2;\n",
        "    size_t sizeA = m * n * sizeof(float);\n",
        "    size_t sizeB = n * p * sizeof(float);\n",
        "    size_t sizeC = m * p * sizeof(float);\n",
        "\n",
        "    // Allocate host memory\n",
        "    float h_A[] = {5, 2, 1, 6};\n",
        "\n",
        "    float h_B[] = {2, 8, 4, 7};\n",
        "\n",
        "    float *h_C = (float *)malloc(sizeC);\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    // Allocate memory on the device for matrix A\n",
        "    cudaMalloc(&d_A, sizeA);\n",
        "\n",
        "    // Allocate memory on the device for matrix B\n",
        "    cudaMalloc(&d_B, sizeB);\n",
        "\n",
        "    // Allocate memory on the device for matrix C\n",
        "    cudaMalloc(&d_C, sizeC);\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_A, h_A, sizeA, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, sizeB, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block size and grid size\n",
        "    dim3 threadsPerBlock(2, 2);  // Adjusted for the 2x2 matrix\n",
        "    dim3 blocksPerGrid(1, 1);    // Only one block is needed\n",
        "\n",
        "    // Launch the kernel\n",
        "    // matrixMulKernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, m, n, p);\n",
        "    // cudaDeviceSynchronize();  // Ensure all threads have finished\n",
        "\n",
        "    // Copy the result back to the host\n",
        "    cudaMemcpy(h_C, d_C, sizeC, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Copy the result matrix C from device to host\n",
        "    cudaMemcpy(h_C, d_C, sizeC, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the result\n",
        "    printf(\"Resulting Matrix C:\\n\");\n",
        "    for (int i = 0; i < m; i++) {\n",
        "        for (int j = 0; j < p; j++) {\n",
        "            printf(\"%f \", h_C[i * p + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    // Free memory allocated for matrix A on the device\n",
        "    free(h_A);\n",
        "\n",
        "    // Free memory allocated for matrix B on the device\n",
        "    free(h_B);\n",
        "\n",
        "    // Free memory allocated for matrix C on the device\n",
        "    free(h_C);\n",
        "\n",
        "    // Free host memory\n",
        "    // Free memory allocated for matrix C on the host\n",
        "    cudaFree(d_A);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwmVzcUjjF25"
      },
      "source": [
        "## QUESTION 2 - BONUS ⭐\n",
        "(Will not be counted for while validating the submission of Assignment 5 but we strongly encourage you to solve this one)\n",
        "\n",
        "Your final task is to create a kernel for block matrix multiplication in CUDA and run it on PyTorch.\n",
        "You must test this kernel in CUDA via nvcc as well and profile it with nvprof with naive matrix multiplication or strassens algorithm.\n",
        "Try out various execution configuration for each run and see the different via profiler.\n",
        "Attach your code snippet here and also share your analysis if any."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
